{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All data cleaning and transformation described in:\n",
    "# http://blog.districtdatalabs.com/building-a-classifier-from-census-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>martial-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        martial-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'martial-status',\n",
    "         'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "          'hours-per-week', 'native-country', 'income']\n",
    "data = pd.read_csv('data/adult.data', names=header)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "meta = {\n",
    "    'target_names': list(data.income.unique()),\n",
    "    'feature_names': list(data.columns),\n",
    "    'categorical_features': {\n",
    "        column: list(data[column].unique())\n",
    "        for column in data.columns\n",
    "        if data[column].dtype == 'object'\n",
    "    },\n",
    "}\n",
    "\n",
    "with open('data/meta.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.base import Bunch\n",
    "\n",
    "def load_data(root='data'):\n",
    "    # Load the meta data from the file\n",
    "    with open(os.path.join(root, 'meta.json'), 'r') as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    names = meta['feature_names']\n",
    "    \n",
    "    # Load the training and test data, skipping the bad row in the test data\n",
    "    train = pd.read_csv(os.path.join(root, 'adult.data'), names=names)\n",
    "    test  = pd.read_csv(os.path.join(root, 'adult.test'), names=names, skiprows=1)\n",
    "\n",
    "    # Remove the target from the categorical features\n",
    "    meta['categorical_features'].pop('income')\n",
    "\n",
    "    # Return the bunch with the appropriate data chunked apart\n",
    "    return Bunch(\n",
    "        data = train[names[:-1]],\n",
    "        target = train[names[-1]],\n",
    "        data_test = test[names[:-1]],\n",
    "        target_test = test[names[-1]],\n",
    "        target_names = meta['target_names'],\n",
    "        feature_names = meta['feature_names'],\n",
    "        categorical_features = meta['categorical_features']\n",
    "    )\n",
    "\n",
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns  = columns\n",
    "        self.encoders = None\n",
    "\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to encode.\n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "\n",
    "        # Fit a label encoder for each column in the data frame\n",
    "        self.encoders = {\n",
    "            column: LabelEncoder().fit(data[column])\n",
    "            for column in self.columns\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame.\n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        for column, encoder in self.encoders.items():\n",
    "            output[column] = encoder.transform(data[column])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "class ImputeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.imputer = None\n",
    "\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to impute.\n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "\n",
    "        # Fit an imputer for each column in the data frame\n",
    "        self.imputer = Imputer(missing_values=0, strategy='most_frequent')\n",
    "        self.imputer.fit(data[self.columns])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame.\n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        output[self.columns] = self.imputer.transform(output[self.columns])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "yencode = LabelEncoder().fit(dataset.target)\n",
    "Y = yencode.transform([y.rstrip(\".\") for y in dataset.target])\n",
    "\n",
    "Y_TEST = yencode.transform([y.rstrip(\".\") for y in dataset.target_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census = Pipeline([\n",
    "        ('encoder',  EncodeCategorical(dataset.categorical_features.keys())),\n",
    "        ('imputer', ImputeCategorical(['workclass', 'native-country', 'occupation']))\n",
    "])\n",
    "X = census.fit_transform(dataset.data)\n",
    "X_TEST = census.fit_transform(dataset.data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 6513  6514  6515 ..., 32558 32559 32560] TEST: [   0    1    2 ..., 6510 6511 6512]\n",
      "TRAIN: [    0     1     2 ..., 32558 32559 32560] TEST: [ 6513  6514  6515 ..., 13022 13023 13024]\n",
      "TRAIN: [    0     1     2 ..., 32558 32559 32560] TEST: [13025 13026 13027 ..., 19534 19535 19536]\n",
      "TRAIN: [    0     1     2 ..., 32558 32559 32560] TEST: [19537 19538 19539 ..., 26046 26047 26048]\n",
      "TRAIN: [    0     1     2 ..., 26046 26047 26048] TEST: [26049 26050 26051 ..., 32558 32559 32560]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "number_of_samples = Y.shape[0]\n",
    "\n",
    "X_map = {0: [], 1: [], 2: [], 3: []}\n",
    "Y_map = {0: [], 1: [], 2: [], 3: []}\n",
    "\n",
    "for fold_idx, indexes in enumerate(kf.split(X, Y)):\n",
    "    train_index, test_index = indexes[0], indexes[1]\n",
    "\n",
    "    print (\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    first_test_idx, last_test_idx = test_index[0], test_index[-1]\n",
    "    \n",
    "    train_data = X[:first_test_idx].append(X[last_test_idx:number_of_samples-1])\n",
    "    #test_data  = Y[first_test_idx:last_test_idx]\n",
    "    \n",
    "    #test_data = Y[:first_test_idx] + Y[last_test_idx:number_of_samples-1]\n",
    "    test_data = np.concatenate((Y[:first_test_idx], Y[last_test_idx:number_of_samples-1]), axis=0)\n",
    "\n",
    "    X_map[fold_idx] = train_data\n",
    "    Y_map[fold_idx] = test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797309747559\n",
      "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(2, 2, 2), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=True, warm_start=False)\n",
      "0.236226276027\n",
      "0.802284871937\n",
      "0.763773723973\n",
      "0.801854922916\n"
     ]
    }
   ],
   "source": [
    "# train 4 different classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "first_KNN = KNeighborsClassifier(n_neighbors=10)\n",
    "first_KNN.fit(X_map[0], Y_map[0])\n",
    "\n",
    "Y_predicted = first_KNN.predict(X_TEST)\n",
    "print(accuracy_score(Y_TEST, Y_predicted))\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "second_NN = MLPClassifier(hidden_layer_sizes=(2, 2, 2), solver='lbfgs', alpha=0.01, verbose=True)\n",
    "print(second_NN)\n",
    "second_NN.fit(X_map[1], Y_map[1])\n",
    "Y_predicted = second_NN.predict(X_TEST)\n",
    "print(accuracy_score(Y_TEST, Y_predicted))\n",
    "\n",
    "#######################################################################################\n",
    "third_NN = LinearSVC(C=1.0, dual=False)\n",
    "third_NN.fit(X_map[2], Y_map[2])\n",
    "Y_predicted = third_NN.predict(X_TEST)\n",
    "print (accuracy_score(Y_TEST, Y_predicted))\n",
    "\n",
    "########################################################################################\n",
    "fourth_NN = SVC(kernel='rbf', C=0.1)\n",
    "fourth_NN.fit(X_map[3], Y_map[3])\n",
    "Y_predicted = fourth_NN.predict(X_TEST)\n",
    "print (accuracy_score(Y_TEST, Y_predicted))\n",
    "\n",
    "##################################\n",
    "fifth_NN = KNeighborsClassifier(n_neighbors=25)\n",
    "fifth_NN.fit(X_map[4], Y_map[4])\n",
    "Y_predicted = fifth_NN.predict(X_TEST)\n",
    "print (accuracy_score(Y_TEST, Y_predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class SimpleVotingClassifier():\n",
    "    predicted = {}\n",
    "    \n",
    "    def __init__(self, classifiers):\n",
    "        self.classifiers = classifiers\n",
    "\n",
    "    def predict(self, X):\n",
    "        number_of_elems = len(X)\n",
    "        print (number_of_elems)\n",
    "        for cl_idx, classifier in enumerate(self.classifiers):\n",
    "            result = classifier.predict(X)\n",
    "            self.predicted[cl_idx] = result\n",
    "        final_results = self.vote()\n",
    "        return final_results\n",
    "    \n",
    "    def vote_for_elem(self, keys):\n",
    "        counter = Counter(keys)\n",
    "        common = counter.most_common()\n",
    "        return counter.most_common()[0][0]\n",
    "    \n",
    "    def vote(self):\n",
    "        print (\"Voting!\")\n",
    "        number_of_elems = len(self.predicted[0])\n",
    "        partial_results = []\n",
    "        for idx in range(number_of_elems):\n",
    "            keys = []\n",
    "            for key in self.predicted.keys():\n",
    "                keys.append(self.predicted[key][idx])\n",
    "            voting_result = self.vote_for_elem(keys)\n",
    "            partial_results.append(voting_result)\n",
    "            keys = []\n",
    "        return partial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16281\n",
      "Voting!\n",
      "0.806707204717\n"
     ]
    }
   ],
   "source": [
    "vc = SimpleVotingClassifier([first_KNN, second_NN, third_NN, fourth_NN, fifth_NN])\n",
    "Y_predicted = vc.predict(np.array(X_TEST))\n",
    "print (accuracy_score(Y_TEST, Y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
